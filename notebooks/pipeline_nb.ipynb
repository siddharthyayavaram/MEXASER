{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "from statistics import mean, stdev\n",
    "import imblearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ravdess = \"data/audio_speech_actors_01-24/\"\n",
    "Savee = \"savee/ALL/\"\n",
    "emodb = \"emodb/wav/\"\n",
    "Tess = \"../archive/TESS Toronto emotional speech set data/TESS Toronto emotional speech set data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>../archive/TESS Toronto emotional speech set d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>../archive/TESS Toronto emotional speech set d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>../archive/TESS Toronto emotional speech set d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "      <td>../archive/TESS Toronto emotional speech set d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>../archive/TESS Toronto emotional speech set d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0    angry  ../archive/TESS Toronto emotional speech set d...\n",
       "1    angry  ../archive/TESS Toronto emotional speech set d...\n",
       "2    angry  ../archive/TESS Toronto emotional speech set d...\n",
       "3    angry  ../archive/TESS Toronto emotional speech set d...\n",
       "4    angry  ../archive/TESS Toronto emotional speech set d..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "df = pd.concat([emotion_df, path_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for i in df.Emotions[:]:\n",
    "    Y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "\n",
    "for i in range(2800):\n",
    "    paths.append(df['Path'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [05:28<00:00,  8.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "\n",
    "X = pd.DataFrame()\n",
    "\n",
    "# Define the feature set you want to use\n",
    "feature_set = opensmile.FeatureSet.ComParE_2016\n",
    "\n",
    "# Initialize opensmile with the chosen feature set\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=feature_set,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "for i in tqdm(paths):\n",
    "    features = smile.process_file(i)\n",
    "    # features_transposed = features.transpose()  # Transpose the DataFrame\n",
    "    X = pd.concat([X, features], axis=0, ignore_index=True)\n",
    "\n",
    "# # Reset column names to integer index\n",
    "X.columns = range(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6363</th>\n",
       "      <th>6364</th>\n",
       "      <th>6365</th>\n",
       "      <th>6366</th>\n",
       "      <th>6367</th>\n",
       "      <th>6368</th>\n",
       "      <th>6369</th>\n",
       "      <th>6370</th>\n",
       "      <th>6371</th>\n",
       "      <th>6372</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.409512</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204863</td>\n",
       "      <td>0.589691</td>\n",
       "      <td>1.011887</td>\n",
       "      <td>0.384828</td>\n",
       "      <td>0.422196</td>\n",
       "      <td>0.807024</td>\n",
       "      <td>0.030353</td>\n",
       "      <td>...</td>\n",
       "      <td>5.348729</td>\n",
       "      <td>0.289192</td>\n",
       "      <td>4.242554</td>\n",
       "      <td>4.327974</td>\n",
       "      <td>-17.914936</td>\n",
       "      <td>0.608820</td>\n",
       "      <td>152.885727</td>\n",
       "      <td>83.054291</td>\n",
       "      <td>172.459793</td>\n",
       "      <td>75.942635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916712</td>\n",
       "      <td>0.188312</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.184017</td>\n",
       "      <td>0.375766</td>\n",
       "      <td>0.684931</td>\n",
       "      <td>0.191749</td>\n",
       "      <td>0.309165</td>\n",
       "      <td>0.500914</td>\n",
       "      <td>0.016434</td>\n",
       "      <td>...</td>\n",
       "      <td>6.557486</td>\n",
       "      <td>0.334924</td>\n",
       "      <td>3.963181</td>\n",
       "      <td>4.109989</td>\n",
       "      <td>-15.706089</td>\n",
       "      <td>0.554739</td>\n",
       "      <td>190.921707</td>\n",
       "      <td>93.375954</td>\n",
       "      <td>165.881805</td>\n",
       "      <td>115.629372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.463523</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.174246</td>\n",
       "      <td>0.380847</td>\n",
       "      <td>0.798810</td>\n",
       "      <td>0.206601</td>\n",
       "      <td>0.417963</td>\n",
       "      <td>0.624564</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>...</td>\n",
       "      <td>9.870838</td>\n",
       "      <td>0.476234</td>\n",
       "      <td>4.304881</td>\n",
       "      <td>4.323459</td>\n",
       "      <td>-19.924049</td>\n",
       "      <td>0.498563</td>\n",
       "      <td>180.678787</td>\n",
       "      <td>100.956093</td>\n",
       "      <td>193.420212</td>\n",
       "      <td>131.130020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.530983</td>\n",
       "      <td>0.169935</td>\n",
       "      <td>0.692810</td>\n",
       "      <td>0.178458</td>\n",
       "      <td>0.553597</td>\n",
       "      <td>0.974556</td>\n",
       "      <td>0.375139</td>\n",
       "      <td>0.420959</td>\n",
       "      <td>0.796099</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>...</td>\n",
       "      <td>4.892866</td>\n",
       "      <td>0.271253</td>\n",
       "      <td>3.832680</td>\n",
       "      <td>3.775176</td>\n",
       "      <td>18.664227</td>\n",
       "      <td>0.740595</td>\n",
       "      <td>140.893097</td>\n",
       "      <td>87.829964</td>\n",
       "      <td>146.642090</td>\n",
       "      <td>73.038651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.358880</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.267951</td>\n",
       "      <td>0.484316</td>\n",
       "      <td>0.670793</td>\n",
       "      <td>0.216365</td>\n",
       "      <td>0.186477</td>\n",
       "      <td>0.402842</td>\n",
       "      <td>0.024349</td>\n",
       "      <td>...</td>\n",
       "      <td>7.889145</td>\n",
       "      <td>0.459729</td>\n",
       "      <td>3.824991</td>\n",
       "      <td>3.944466</td>\n",
       "      <td>-16.407700</td>\n",
       "      <td>0.500121</td>\n",
       "      <td>199.191910</td>\n",
       "      <td>101.266716</td>\n",
       "      <td>98.194481</td>\n",
       "      <td>41.534412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>1.185210</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.646512</td>\n",
       "      <td>0.204553</td>\n",
       "      <td>0.371865</td>\n",
       "      <td>0.602021</td>\n",
       "      <td>0.167312</td>\n",
       "      <td>0.230156</td>\n",
       "      <td>0.397468</td>\n",
       "      <td>0.074873</td>\n",
       "      <td>...</td>\n",
       "      <td>5.458078</td>\n",
       "      <td>0.457947</td>\n",
       "      <td>2.452641</td>\n",
       "      <td>2.440002</td>\n",
       "      <td>19.871544</td>\n",
       "      <td>0.504870</td>\n",
       "      <td>123.588638</td>\n",
       "      <td>59.071106</td>\n",
       "      <td>97.787613</td>\n",
       "      <td>58.579617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>1.072646</td>\n",
       "      <td>0.179612</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.216095</td>\n",
       "      <td>0.404453</td>\n",
       "      <td>0.597532</td>\n",
       "      <td>0.188358</td>\n",
       "      <td>0.193079</td>\n",
       "      <td>0.381437</td>\n",
       "      <td>0.042804</td>\n",
       "      <td>...</td>\n",
       "      <td>6.242836</td>\n",
       "      <td>0.525422</td>\n",
       "      <td>2.299856</td>\n",
       "      <td>2.361291</td>\n",
       "      <td>-16.995899</td>\n",
       "      <td>0.455454</td>\n",
       "      <td>109.777870</td>\n",
       "      <td>67.006943</td>\n",
       "      <td>88.109619</td>\n",
       "      <td>51.920315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>0.980292</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.693023</td>\n",
       "      <td>0.215134</td>\n",
       "      <td>0.384987</td>\n",
       "      <td>0.728419</td>\n",
       "      <td>0.169853</td>\n",
       "      <td>0.343431</td>\n",
       "      <td>0.513285</td>\n",
       "      <td>0.085830</td>\n",
       "      <td>...</td>\n",
       "      <td>6.561334</td>\n",
       "      <td>0.509982</td>\n",
       "      <td>2.274836</td>\n",
       "      <td>2.306772</td>\n",
       "      <td>-18.804390</td>\n",
       "      <td>0.464993</td>\n",
       "      <td>111.616272</td>\n",
       "      <td>62.557739</td>\n",
       "      <td>86.448982</td>\n",
       "      <td>50.563286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>1.047530</td>\n",
       "      <td>0.181416</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>0.176108</td>\n",
       "      <td>0.254267</td>\n",
       "      <td>0.579653</td>\n",
       "      <td>0.078159</td>\n",
       "      <td>0.325386</td>\n",
       "      <td>0.403545</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>...</td>\n",
       "      <td>4.526168</td>\n",
       "      <td>0.428460</td>\n",
       "      <td>2.143402</td>\n",
       "      <td>2.171680</td>\n",
       "      <td>-18.926029</td>\n",
       "      <td>0.596808</td>\n",
       "      <td>100.704506</td>\n",
       "      <td>52.543175</td>\n",
       "      <td>87.989960</td>\n",
       "      <td>41.919945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>1.117586</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178299</td>\n",
       "      <td>0.262807</td>\n",
       "      <td>0.552652</td>\n",
       "      <td>0.084508</td>\n",
       "      <td>0.289845</td>\n",
       "      <td>0.374353</td>\n",
       "      <td>0.070111</td>\n",
       "      <td>...</td>\n",
       "      <td>4.997362</td>\n",
       "      <td>0.475216</td>\n",
       "      <td>1.847707</td>\n",
       "      <td>1.817782</td>\n",
       "      <td>18.489799</td>\n",
       "      <td>0.684306</td>\n",
       "      <td>97.696472</td>\n",
       "      <td>50.209148</td>\n",
       "      <td>89.583679</td>\n",
       "      <td>63.649632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 6373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     1.409512  0.452055  0.000000  0.204863  0.589691  1.011887  0.384828   \n",
       "1     0.916712  0.188312  0.701299  0.184017  0.375766  0.684931  0.191749   \n",
       "2     1.463523  0.170068  0.693878  0.174246  0.380847  0.798810  0.206601   \n",
       "3     1.530983  0.169935  0.692810  0.178458  0.553597  0.974556  0.375139   \n",
       "4     1.358880  0.174242  0.696970  0.267951  0.484316  0.670793  0.216365   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2795  1.185210  0.200000  0.646512  0.204553  0.371865  0.602021  0.167312   \n",
       "2796  1.072646  0.179612  0.718447  0.216095  0.404453  0.597532  0.188358   \n",
       "2797  0.980292  0.209302  0.693023  0.215134  0.384987  0.728419  0.169853   \n",
       "2798  1.047530  0.181416  0.654867  0.176108  0.254267  0.579653  0.078159   \n",
       "2799  1.117586  0.191304  0.000000  0.178299  0.262807  0.552652  0.084508   \n",
       "\n",
       "          7         8         9     ...      6363      6364      6365  \\\n",
       "0     0.422196  0.807024  0.030353  ...  5.348729  0.289192  4.242554   \n",
       "1     0.309165  0.500914  0.016434  ...  6.557486  0.334924  3.963181   \n",
       "2     0.417963  0.624564  0.017857  ...  9.870838  0.476234  4.304881   \n",
       "3     0.420959  0.796099  0.015183  ...  4.892866  0.271253  3.832680   \n",
       "4     0.186477  0.402842  0.024349  ...  7.889145  0.459729  3.824991   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2795  0.230156  0.397468  0.074873  ...  5.458078  0.457947  2.452641   \n",
       "2796  0.193079  0.381437  0.042804  ...  6.242836  0.525422  2.299856   \n",
       "2797  0.343431  0.513285  0.085830  ...  6.561334  0.509982  2.274836   \n",
       "2798  0.325386  0.403545  0.046640  ...  4.526168  0.428460  2.143402   \n",
       "2799  0.289845  0.374353  0.070111  ...  4.997362  0.475216  1.847707   \n",
       "\n",
       "          6366       6367      6368        6369        6370        6371  \\\n",
       "0     4.327974 -17.914936  0.608820  152.885727   83.054291  172.459793   \n",
       "1     4.109989 -15.706089  0.554739  190.921707   93.375954  165.881805   \n",
       "2     4.323459 -19.924049  0.498563  180.678787  100.956093  193.420212   \n",
       "3     3.775176  18.664227  0.740595  140.893097   87.829964  146.642090   \n",
       "4     3.944466 -16.407700  0.500121  199.191910  101.266716   98.194481   \n",
       "...        ...        ...       ...         ...         ...         ...   \n",
       "2795  2.440002  19.871544  0.504870  123.588638   59.071106   97.787613   \n",
       "2796  2.361291 -16.995899  0.455454  109.777870   67.006943   88.109619   \n",
       "2797  2.306772 -18.804390  0.464993  111.616272   62.557739   86.448982   \n",
       "2798  2.171680 -18.926029  0.596808  100.704506   52.543175   87.989960   \n",
       "2799  1.817782  18.489799  0.684306   97.696472   50.209148   89.583679   \n",
       "\n",
       "            6372  \n",
       "0      75.942635  \n",
       "1     115.629372  \n",
       "2     131.130020  \n",
       "3      73.038651  \n",
       "4      41.534412  \n",
       "...          ...  \n",
       "2795   58.579617  \n",
       "2796   51.920315  \n",
       "2797   50.563286  \n",
       "2798   41.919945  \n",
       "2799   63.649632  \n",
       "\n",
       "[2800 rows x 6373 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = X\n",
    "Features['labels'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.head()\n",
    "Features.to_csv('../feature_csvs/tess_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = pd.read_csv('tess_features.csv')\n",
    "Features.head()\n",
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2800, 6373), (2800,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is a multiclass classification problem onehotencoding our Y.\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "# splitting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size=0.1,random_state=4, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "# scaling our data with sklearn's Standard scaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Step 1: Convert one-hot encoded labels back to numerical labels\n",
    "y_train = y_train.argmax(axis=1)\n",
    "y_test = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1: 0.9964285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# Step 2: Create an SVM classifier\n",
    "svm_classifier = svm.SVC(kernel='rbf', C=100)  # You can choose different parameters based on your data\n",
    "\n",
    "# Step 3: Train the SVM classifier\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions on the test set\n",
    "y_test_pred = svm_classifier.predict(x_test)\n",
    "\n",
    "# Step 5: Evaluate the model on the test set\n",
    "precision = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test f1:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=5, random_state=4)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_classifier = XGBClassifier(n_estimators=10, random_state=4)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {\n",
    "    0: 'neutral',\n",
    "    1: 'calm',\n",
    "    2: 'happy',\n",
    "    3: 'sad',\n",
    "    4: 'angry',\n",
    "    5: 'fearful',\n",
    "    6: 'disgust',\n",
    "    7: 'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       1.00      1.00      1.00        46\n",
      "        calm       1.00      1.00      1.00        48\n",
      "     disgust       0.98      1.00      0.99        43\n",
      "     fearful       1.00      1.00      1.00        29\n",
      "       happy       1.00      1.00      1.00        38\n",
      "     neutral       1.00      1.00      1.00        37\n",
      "         sad       1.00      0.97      0.99        39\n",
      "\n",
      "    accuracy                           1.00       280\n",
      "   macro avg       1.00      1.00      1.00       280\n",
      "weighted avg       1.00      1.00      1.00       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true_emotions = np.array([emotion_dict[label] for label in y_test])\n",
    "y_pred_emotions = np.array([emotion_dict[label] for label in y_test_pred])\n",
    "\n",
    "# Generate a new classification report\n",
    "report_with_emotions = classification_report(y_true_emotions, y_pred_emotions)\n",
    "\n",
    "# Display the new classification report\n",
    "print(report_with_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(x_train)\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_knn(features):\n",
    "    features = features.astype(int)\n",
    "    X_train_subset = x_train_df.iloc[:, features]\n",
    "    X_test_subset = x_test_df.iloc[:, features]\n",
    "    X_test_subset = np.array(X_test_subset)  # Ensure X_test_subset is a NumPy array\n",
    "    if not X_test_subset.flags.c_contiguous:  # Check contiguity and make it contiguous if necessary\n",
    "        X_test_subset = np.ascontiguousarray(X_test_subset)\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn_classifier.fit(X_train_subset, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test_subset)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642857142857143"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_knn(np.array(list(range(6372))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective_info_gain(np.array(list(range(100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mealpy import IntegerVar,GA,DE,CRO,EP,HS,WCA,AEO,GCO,FA,QSA,SHADE\n",
    "\n",
    "def objective_knn(features):\n",
    "    features = features.astype(int)\n",
    "    X_train_subset = x_train_df.iloc[:, features]\n",
    "    X_test_subset = x_test_df.iloc[:, features]\n",
    "    X_test_subset = np.array(X_test_subset)  # Ensure X_test_subset is a NumPy array\n",
    "    if not X_test_subset.flags.c_contiguous:  # Check contiguity and make it contiguous if necessary\n",
    "        X_test_subset = np.ascontiguousarray(X_test_subset)\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn_classifier.fit(X_train_subset, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test_subset)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc\n",
    "\n",
    "def objective_info_gain(features):\n",
    "    features = features.astype(int)\n",
    "    X_train_subset = x_train_df.iloc[:, features]\n",
    "    info_gain = mutual_info_classif(X_train_subset, y_train)  # Calculate information gain for each feature\n",
    "    return np.sum(info_gain)  # Sum of information gains of selected features\n",
    "\n",
    "def objective_svm(features):\n",
    "    features = features.astype(int)\n",
    "    X_train_subset = x_train_df.iloc[:, features]\n",
    "    X_test_subset = x_test_df.iloc[:, features]\n",
    "    svm_classifier_rbf = svm.SVC(kernel='rbf', C=100)\n",
    "    svm_classifier_rbf.fit(X_train_subset, y_train)\n",
    "    y_pred = svm_classifier_rbf.predict(X_test_subset)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc\n",
    "\n",
    "problem_dict = {\n",
    "    \"obj_func\": objective_svm,\n",
    "    \"bounds\": IntegerVar(lb=[0, ] * 50, ub=[6372, ] * 50,),\n",
    "    \"minmax\": \"max\",\n",
    "}\n",
    "\n",
    "# optimizer = GA.BaseGA(epoch=100, pop_size=64, pc=0.95, pm=0.1)\n",
    "# optimizer = CRO.OCRO(epoch=100, pop_size=64, po = 0.4, Fb = 0.9, Fa = 0.1, Fd = 0.1, Pd = 0.5, GCR = 0.1, gamma_min = 0.02, gamma_max = 0.2, n_trials = 5, restart_count = 50)\n",
    "# optimizer = DE.JADE(epoch=1000, pop_size=50, miu_f = 0.5, miu_cr = 0.5, pt = 0.1, ap = 0.1)  # decent\n",
    "# optimizer = HS.DevHS(epoch=100, pop_size=64, c_r = 0.95, pa_r = 0.05)\n",
    "# optimizer = AEO.AugmentedAEO(epoch=100, pop_size=64)    good\n",
    "# optimizer =  WCA.OriginalWCA(epoch=1000, pop_size=64, nsr = 4, wc = 2.0, dmax = 1e-6) # good WCA\n",
    "# optimizer = FA.OriginalFA(epoch=100, pop_size=64, max_sparks = 50, p_a = 0.04, p_b = 0.8, max_ea = 40, m_sparks = 50) #   decent\n",
    "# optimizer =   QSA.ImprovedQSA(epoch=1000, pop_size=64)  alright\n",
    "# optimizer = SHADE.L_SHADE(epoch=1000, pop_size=50, miu_f = 0.5, miu_cr = 0.5)\n",
    "\n",
    "optimizer = GA.BaseGA(epoch=100, pop_size=64, pc=0.95, pm=0.1)\n",
    "optimizer.solve(problem_dict)\n",
    "\n",
    "print(optimizer.g_best.solution)\n",
    "print(optimizer.g_best.target.fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective_rf(features):\n",
    "    features = features.astype(int)\n",
    "    X_train_subset = x_train_df.iloc[:, features]\n",
    "    X_test_subset = x_test_df.iloc[:, features]\n",
    "    random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    random_forest_classifier.fit(X_train_subset, y_train)\n",
    "    y_pred = random_forest_classifier.predict(X_test_subset)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_sol = optimizer.g_best.solution\n",
    "main_sol_int = main_sol.astype(int)\n",
    "np.save('tess_50_opensm_svm_100percent.npy',main_sol_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857142857142858"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.load('opensmile_100_svm.npy')\n",
    "objective_rf(main_sol_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_svm_f1(features):\n",
    "    features = features.astype(int)\n",
    "    X_train_subset = x_train_df.iloc[:, features]\n",
    "    X_test_subset = x_test_df.iloc[:, features]\n",
    "    svm_classifier_rbf = svm.SVC(kernel='rbf', C=100)\n",
    "    svm_classifier_rbf.fit(X_train_subset, y_train)\n",
    "    y_pred = svm_classifier_rbf.predict(X_test_subset)\n",
    "    from sklearn.metrics import classification_report\n",
    "    y_true_emotions = np.array([emotion_dict[label] for label in y_test])\n",
    "    y_pred_emotions = np.array([emotion_dict[label] for label in y_pred])\n",
    "\n",
    "    # Generate a new classification report\n",
    "    report_with_emotions = classification_report(y_true_emotions, y_pred_emotions)\n",
    "\n",
    "    # Display the new classification report\n",
    "    print(report_with_emotions)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([4484, 5220, 5819, 2352, 3971, 2798, 2313, 896, 3702, 142, 1838, 1827, 2192, 3207, 282, 1754, 4816, 5308, 6300, 4397, 3662, 1815, 4390, 1893, 2778, 37, 3713, 6366, 6255, 2336, 1322, 3692, 3673, 5667, 1191, 3962, 1490, 4634, 1139, 96, 5045, 4854, 2934, 1530, 801, 2282, 1858, 1671, 5172, 5424, 4752, 1849, 2073, 4591, 4721, 5811, 3250, 448, 4790, 784, 6230, 372, 3551, 4452, 3902, 4560, 1543, 4201, 5737, 1114, 4208, 4561, 2847, 2267, 3778, 4032, 3714, 5418, 1426, 4756, 4190, 5746, 4416, 3567, 2319, 4644, 3017, 5219, 3525, 2573, 671, 1218, 3423, 1068, 3954, 464, 395, 5613, 1664, 2600, 1015, 5405, 5177, 1791, 5265, 459, 5369, 2877, 3677, 4141, 4865, 5669, 4159, 2608, 3423, 1626, 3239, 6198, 4548, 2877, 4313, 4861, 5005, 3314, 4271, 2241, 6174, 461, 6249, 1453, 2076, 2081, 2661, 2005, 5283, 3867, 5878, 4057, 2380, 4242, 6261, 2336, 2950, 2240, 6199, 1747, 1378, 157, 4612, 3211, 4616, 5619, 5258, 566, 5309, 5998, 5652, 5180, 5304, 1649, 2695, 3058, 374, 5006, 5273, 1530, 5141, 4364, 3166, 3062, 4816, 3516, 3731, 4304, 2648, 2392, 5906, 4761, 4795, 865, 2638, 4325, 839, 9, 989, 5697, 786, 2907, 1170, 4375, 6344, 1075, 349, 1688, 4483, 1864, 3855, 5546, 1441, 2551, 2425, 5540, 796, 1128, 5447, 5381, 4837, 2253, 3176, 4984, 5121, 241, 3731, 5881, 973, 5668, 2135, 4301, 1927, 2632, 5561, 1090, 1609, 5783, 2357, 2564, 606, 3756, 3912, 920, 2128, 218, 5022, 1663, 1038, 1714, 1046, 2908, 5587, 5819, 5546, 2236, 3756, 766, 1271, 5582, 3054, 3885, 3142, 609])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([5353, 4170, 510, 5395, 1754, 1581, 5875, 159, 5213, 2843, 3337, 2979, 2465, 5740, 6175, 125, 2175, 4568, 2170, 199, 1455, 5297, 4354, 3537, 837, 4960, 3664, 945, 4908, 3396, 1771, 3278, 2368, 5418, 6220, 3881, 2369, 1882, 5537, 2441, 1559, 4238, 5684, 5579, 4025, 4812, 433, 6225, 2076, 3490, 5034, 2273, 1838, 4010, 4236, 1188, 2398, 601, 3666, 1786, 1400, 5757, 1526, 4559, 242, 2448, 6204, 1149, 4830, 5632, 297, 4705, 2358, 994, 5792, 2316, 966, 1957, 824, 15, 5116, 3689, 696, 3238, 2406, 1678, 6199, 192, 3666, 3694, 1943, 1476, 6012, 348, 1801, 6155, 1843, 3679, 5359, 2068, 2361, 4569, 220, 3857, 2322, 3528, 6020, 1762, 3605, 5822, 4790, 1820, 975, 4714, 5870, 3292, 2966, 1094, 6100, 6210, 2846, 5343, 1647, 2127, 5030, 3026, 6180, 6329, 1969, 5529, 1524, 1396, 530, 2116, 1989, 2607, 1424, 4869, 1573, 5189, 5242, 5308, 1559, 6174, 815, 6161, 5136, 3306, 1729, 1167, 5817, 5914, 3283, 1878, 2208, 3595, 207, 2422, 1087, 3233, 1557, 5078, 1654, 651, 5767, 6289, 1681, 6247, 77, 3917, 2701, 2980, 3679, 6013, 1401, 5267, 3678, 228, 2666, 5557, 49, 44, 4963, 1870, 3635, 3458, 3923, 1961, 521, 5865, 3862, 4494, 3855, 4899, 1341, 1377, 1942, 982, 2792, 1739, 5286, 5986, 5119, 1216, 842, 1653, 5540, 239, 3932, 2924, 6013, 1856, 1720, 3165, 3401, 5237, 3515, 5507, 2552, 5356, 3395, 618, 3431, 2939, 517, 5903, 3022, 994, 1144, 877, 2007, 2390, 1610, 3146, 1268, 5501, 257, 854, 2572, 3210, 294, 804, 2092, 4828, 1041, 1499, 70, 3305, 642, 792])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       1.00      1.00      1.00        46\n",
      "        calm       1.00      1.00      1.00        48\n",
      "     disgust       1.00      1.00      1.00        43\n",
      "     fearful       1.00      1.00      1.00        29\n",
      "       happy       1.00      1.00      1.00        38\n",
      "     neutral       1.00      1.00      1.00        37\n",
      "         sad       1.00      1.00      1.00        39\n",
      "\n",
      "    accuracy                           1.00       280\n",
      "   macro avg       1.00      1.00      1.00       280\n",
      "weighted avg       1.00      1.00      1.00       280\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_svm_f1(main_sol_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import datetime\n",
    "from statistics import mean, stdev\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Features['labels'].values\n",
    "data_1 = X[:,main_sol_int]\n",
    "\n",
    "# data_1.shape\n",
    "labels=Y\n",
    "\n",
    "oversample = imblearn.over_sampling.SMOTE()\n",
    "data, labels = oversample.fit_resample(data_1, Y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_scaled = sc.fit_transform(data)\n",
    "\n",
    "y = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = svm.SVC(kernel='rbf', C=100)\n",
    "\n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=4)  # 1 -- 77.91, 4 -- 78\n",
    "lst_accu_stratified = []\n",
    "times = []\n",
    "y_actual_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(x_scaled, labels):\n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    a = datetime.datetime.now()\n",
    "    svclassifier.fit(x_train_fold, y_train_fold)\n",
    "    b = datetime.datetime.now()\n",
    "    lst_accu_stratified.append(svclassifier.score(x_test_fold, y_test_fold))\n",
    "\n",
    "    y_pred = svclassifier.predict(x_test_fold)\n",
    "\n",
    "    times.append((b-a))\n",
    "    #add actual and pred labels to lists\n",
    "    y_actual_list.append(y_test_fold.copy())\n",
    "    y_pred_list.append(y_pred.copy())\n",
    "\n",
    "# s = np.zeros((8,8))\n",
    "\n",
    "for i in range(len(y_actual_list)):\n",
    "    print(\"Fold \",i,\"..................\")\n",
    "    print(\"accuracy = \", lst_accu_stratified[i])\n",
    "    #print(classification_report(y_actual_list[i], y_pred_list[i]))\n",
    "    #print(confusion_matrix(y_actual_list[i], y_pred_list[i]))\n",
    "#     s += confusion_matrix(y_actual_list[i], y_pred_list[i])\n",
    "\n",
    "#print(s)\n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified) * 100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified) * 100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified) * 100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print(\"average time taken by a fold = \", np.asarray(times).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'angry', 'angry', ..., 'sad', 'sad', 'sad'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# # Load iris dataset\n",
    "# iris = datasets.load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# Binarize the labels for multiclass classification\n",
    "y_bin = label_binarize(y, classes=np.unique(y))\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=4, shuffle=True)\n",
    "\n",
    "# Train SVM classifier\n",
    "clf = SVC(kernel='rbf', C= 100,decision_function_shape='ovr')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get decision scores for each sample\n",
    "decision_scores = clf.decision_function(X_test)\n",
    "\n",
    "# Plot box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(decision_scores, patch_artist=True, showmeans=True)\n",
    "plt.xticks(np.arange(1, len(np.unique(y))+1), list(emotion_dict))\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Decision Score')\n",
    "plt.title('Box Plot of Decision Scores for SVM Multiclass Classification')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
